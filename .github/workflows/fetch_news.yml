name: Fetch News

on:
  push:
    branches:
      - main  # Run on push to main branch
      - master  # Run on push to master branch (if you use master)
  schedule:
    # Run daily at 6 AM UTC (adjust timezone as needed)
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      news_type:
        description: 'Type of news to fetch'
        required: true
        default: 'top'
        type: choice
        options:
          - top
          - topic
          - search
          - geo
      topic:
        description: 'Topic for topic headlines'
        required: false
        type: string
      query:
        description: 'Query for search'
        required: false
        type: string
      when:
        description: 'Time period for search (e.g., 1h, 1d)'
        required: false
        type: string
      location:
        description: 'Location for geo news'
        required: false
        type: string
      output_path:
        description: 'Path to save output JSON file'
        required: false
        default: 'data/news.json'
        type: string

jobs:
  fetch-news:
    runs-on: ubuntu-latest
    environment: SUPABASE_URL
    
    # Add permissions to allow pushing to the repository
    permissions:
      contents: write
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        persist-credentials: true
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.8'  # Use 3.8 for better compatibility
    
    - name: Install dependencies
      run: |
        # Show Python and pip versions for debugging
        python --version
        pip --version
        # Install setuptools version that supports use_2to3
        pip install "setuptools<58"
        pip install sgmllib3k
        pip install dateparser
        pip install urllib3
        pip install idna
        pip install certifi
        pip install soupsieve
        pip install charset-normalizer
        pip install chardet
        pip install typing_extensions starlette pydantic
        # Install summarization dependencies
        pip install nltk==3.8.1
        pip install newspaper3k==0.2.8
        pip install 'lxml[html_clean]>=4.9.0'
        pip install lxml_html_clean
        pip install requests-file>=1.5.1
        pip install feedparser>=6.0.0
        pip install tldextract>=3.1.0
        pip install cssselect>=1.1.0
        pip install feedfinder2>=0.0.4
        pip install jieba3k>=0.35.1
        pip install python-dateutil>=2.8.2
        # Install Selenium dependencies
        pip install selenium
        pip install webdriver-manager
        # Download NLTK data
        python -m nltk.downloader punkt
        # Install dependencies from requirements.txt --no-deps
        pip install -r requirements.txt --no-deps
        # List installed packages for debugging
        pip list
    
    - name: Verify installation
      run: |
        python -c "import pygooglenews; print('PyGoogleNews imported successfully')"
        python -c "from pygooglenews import GoogleNews; print('Successfully imported GoogleNews')"
        python -c "import fastapi; print('FastAPI imported successfully')"
    
    - name: Run installation test script
      run: |
        if [ -f scripts/test_installation.py ]; then
          python scripts/test_installation.py
        fi
    
    - name: Fetch top news (scheduled)
      if: github.event_name == 'schedule'
      run: |
        # Create data directory if it doesn't exist
        mkdir -p data
        # General news categories
        python scripts/fetch_news.py --type top --output data/news_top.json
        python scripts/fetch_news.py --type topic --topic technology --output data/news_tech.json
        python scripts/fetch_news.py --type topic --topic business --output data/news_business.json
        # Additional categories like Inshorts
        python scripts/fetch_news.py --type topic --topic entertainment --output data/news_entertainment.json
        python scripts/fetch_news.py --type topic --topic sports --output data/news_sports.json
        python scripts/fetch_news.py --type topic --topic science --output data/news_science.json
        python scripts/fetch_news.py --type topic --topic health --output data/news_health.json
        python scripts/fetch_news.py --type topic --topic world --output data/news_world.json
        # Trending topics
        python scripts/fetch_news.py --type search --query "trending" --when 1d --output data/news_trending.json
    
    - name: Fetch news (manual)
      if: github.event_name == 'workflow_dispatch'
      run: |
        ARGS="--type ${{ github.event.inputs.news_type }} --output ${{ github.event.inputs.output_path }}"
        
        if [ "${{ github.event.inputs.news_type }}" = "topic" ] && [ -n "${{ github.event.inputs.topic }}" ]; then
          ARGS="$ARGS --topic ${{ github.event.inputs.topic }}"
        fi
        
        if [ "${{ github.event.inputs.news_type }}" = "search" ] && [ -n "${{ github.event.inputs.query }}" ]; then
          ARGS="$ARGS --query ${{ github.event.inputs.query }}"
          
          if [ -n "${{ github.event.inputs.when }}" ]; then
            ARGS="$ARGS --when ${{ github.event.inputs.when }}"
          fi
        fi
        
        if [ "${{ github.event.inputs.news_type }}" = "geo" ] && [ -n "${{ github.event.inputs.location }}" ]; then
          ARGS="$ARGS --location ${{ github.event.inputs.location }}"
        fi
        
        mkdir -p $(dirname ${{ github.event.inputs.output_path }})
        python scripts/fetch_news.py $ARGS
    
    - name: Fetch news (push trigger)
      if: github.event_name == 'push'
      run: |
        # Create data directory if it doesn't exist
        mkdir -p data
        # General news categories
        python scripts/fetch_news.py --type top --output data/news_top.json
        python scripts/fetch_news.py --type topic --topic technology --output data/news_tech.json
        python scripts/fetch_news.py --type topic --topic business --output data/news_business.json
        # Additional categories like Inshorts
        python scripts/fetch_news.py --type topic --topic entertainment --output data/news_entertainment.json
        python scripts/fetch_news.py --type topic --topic sports --output data/news_sports.json
        python scripts/fetch_news.py --type topic --topic science --output data/news_science.json
        python scripts/fetch_news.py --type topic --topic health --output data/news_health.json
        python scripts/fetch_news.py --type topic --topic world --output data/news_world.json
        # Trending topics
        python scripts/fetch_news.py --type search --query "trending" --when 1d --output data/news_trending.json
    
    - name: Generate Inshorts-style news
      if: github.event_name == 'push' || github.event_name == 'schedule'
      run: |
        # Check if news files exist
        echo "Checking for news files..."
        ls -la data/
        
        # Set up Chrome for Selenium
        echo "Setting up Chrome for Selenium..."
        wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        
        # Generate Inshorts-style summaries for all news categories
        echo "Generating Inshorts summaries for all categories..."
        python scripts/generate_all_inshorts.py --input-dir data --output-dir data --max-articles 20 --headless
        
        # List generated files
        echo "Generated Inshorts files:"
        ls -la data/inshorts_*
    
    - name: Push to Supabase
      if: github.event_name == 'push' || github.event_name == 'schedule'
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      run: |
        # Check if inshorts files were generated
        echo "Checking for generated inshorts files..."
        if ls data/inshorts_*.json 1> /dev/null 2>&1; then
          echo "Found inshorts files, proceeding with Supabase upload..."
          
          # Push all inshorts data to Supabase
          echo "Uploading inshorts data to Supabase..."
          python scripts/push_inshorts_to_supabase.py
          
          echo "Supabase upload completed!"
        else
          echo "No inshorts files found, skipping Supabase upload"
        fi
    
    - name: Commit and push changes
      if: success() # Only run if previous steps succeeded
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "Update news data - $(date)"
          git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}
          git push
        fi